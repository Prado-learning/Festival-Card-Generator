{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3b8b3368-e6ba-4a81-b803-a07197cd6399",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-01-13T13:58:47.994165Z",
     "iopub.status.busy": "2025-01-13T13:58:47.993823Z",
     "iopub.status.idle": "2025-01-13T13:58:57.144895Z",
     "shell.execute_reply": "2025-01-13T13:58:57.144314Z",
     "shell.execute_reply.started": "2025-01-13T13:58:47.994138Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.cloud.aliyuncs.com/pypi/simple\n",
      "Requirement already satisfied: gradio in /usr/local/lib/python3.10/site-packages (5.8.0)\n",
      "Collecting gradio\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/7a/70/fb8611fabeb432d05946ef89d7acc6fde6c7e85ca9a05d39626b4cdf1a17/gradio-5.12.0-py3-none-any.whl (57.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: openai in /usr/local/lib/python3.10/site-packages (1.57.0)\n",
      "Collecting openai\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/70/45/6de8e5fd670c804b29c777e4716f1916741c71604d5c7d952eee8432f7d3/openai-1.59.6-py3-none-any.whl (454 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting dashscope\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/29/ab/06425bc51305d6acd19cf04736f0fac0cc34b8ced6f31f2d41909a2e1920/dashscope-1.20.14-py3-none-any.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting modelscope_studio\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/99/64/9eb0bb5ad6bc8dcd7282fc762a2fa19615c3f9862fe6e4a8b3104de09e76/modelscope_studio-1.0.2-py3-none-any.whl (11.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m141.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/site-packages (from gradio) (4.6.2.post1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.10/site-packages (from gradio) (0.115.6)\n",
      "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/site-packages (from gradio) (0.4.0)\n",
      "Collecting gradio-client==1.5.4 (from gradio)\n",
      "  Downloading https://mirrors.cloud.aliyuncs.com/pypi/packages/a6/3d/e05202dd42581c2a1e93c730d10a0ef45bc40921332c9aa0d6645bbf0e2b/gradio_client-1.5.4-py3-none-any.whl (321 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m321.4/321.4 kB\u001b[0m \u001b[31m86.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/site-packages (from gradio) (0.28.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/site-packages (from gradio) (0.25.2)\n",
      "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from gradio) (1.26.4)\n",
      "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/site-packages (from gradio) (3.10.12)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.10/site-packages (from gradio) (24.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/site-packages (from gradio) (11.0.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.8.2)\n",
      "Requirement already satisfied: pydub in /usr/local/lib/python3.10/site-packages (from gradio) (0.25.1)\n",
      "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.10/site-packages (from gradio) (0.0.19)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/site-packages (from gradio) (0.8.2)\n",
      "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.10/site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.10/site-packages (from gradio) (0.41.3)\n",
      "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.10/site-packages (from gradio) (0.13.2)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/site-packages (from gradio) (0.15.1)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/site-packages (from gradio) (0.32.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/site-packages (from gradio-client==1.5.4->gradio) (2024.6.1)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in /usr/local/lib/python3.10/site-packages (from gradio-client==1.5.4->gradio) (14.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/site-packages (from openai) (0.8.0)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/site-packages (from openai) (4.67.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/site-packages (from dashscope) (3.11.10)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/site-packages (from dashscope) (2.32.3)\n",
      "Requirement already satisfied: websocket-client in /usr/local/lib/python3.10/site-packages (from dashscope) (1.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /usr/local/lib/python3.10/site-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/site-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/site-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/site-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
      "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->dashscope) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/site-packages (from aiohttp->dashscope) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->dashscope) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->dashscope) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/site-packages (from aiohttp->dashscope) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/site-packages (from aiohttp->dashscope) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->dashscope) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/site-packages (from aiohttp->dashscope) (1.18.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/site-packages (from requests->dashscope) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/site-packages (from requests->dashscope) (2.2.3)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 24.0 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: openai, gradio-client, gradio, dashscope, modelscope_studio\n",
      "  Attempting uninstall: openai\n",
      "    Found existing installation: openai 1.57.0\n",
      "    Uninstalling openai-1.57.0:\n",
      "      Successfully uninstalled openai-1.57.0\n",
      "  Attempting uninstall: gradio-client\n",
      "    Found existing installation: gradio_client 1.5.1\n",
      "    Uninstalling gradio_client-1.5.1:\n",
      "      Successfully uninstalled gradio_client-1.5.1\n",
      "  Attempting uninstall: gradio\n",
      "    Found existing installation: gradio 5.8.0\n",
      "    Uninstalling gradio-5.8.0:\n",
      "      Successfully uninstalled gradio-5.8.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lmdeploy 0.6.2 requires peft<=0.11.1, but you have peft 0.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed dashscope-1.20.14 gradio-5.12.0 gradio-client-1.5.4 modelscope_studio-1.0.2 openai-1.59.6\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.3.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install gradio openai dashscope  modelscope_studio --pre -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23fcc7ce-a217-4e56-a898-b2a4a7b62f3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-13T13:59:08.897852Z",
     "iopub.status.busy": "2025-01-13T13:59:08.897536Z",
     "iopub.status.idle": "2025-01-13T13:59:08.901174Z",
     "shell.execute_reply": "2025-01-13T13:59:08.900619Z",
     "shell.execute_reply.started": "2025-01-13T13:59:08.897832Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dsw-811540/proxy/7860\n"
     ]
    }
   ],
   "source": [
    "# 仅在 Notebook 中运行时需要，本地运行无需该部分\n",
    "import os\n",
    "os.environ['GRADIO_ROOT_PATH'] = f\"/{os.environ['JUPYTER_NAME']}/proxy/7860\"\n",
    "print(os.environ['GRADIO_ROOT_PATH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76e84121-7d24-46a9-b5e8-87a58d80ab8b",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-01-13T13:59:10.982642Z",
     "iopub.status.busy": "2025-01-13T13:59:10.982298Z",
     "iopub.status.idle": "2025-01-13T13:59:11.216582Z",
     "shell.execute_reply": "2025-01-13T13:59:11.216068Z",
     "shell.execute_reply.started": "2025-01-13T13:59:10.982618Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import dashscope\n",
    "dashscope.api_key = \"sk-1d9f630ab5a34072b30ac4630021a643\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ab6aaac-8be9-4ed9-9541-68a163af10a5",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2025-01-13T13:59:12.712374Z",
     "iopub.status.busy": "2025-01-13T13:59:12.711790Z",
     "iopub.status.idle": "2025-01-13T13:59:45.514218Z",
     "shell.execute_reply": "2025-01-13T13:59:45.513707Z",
     "shell.execute_reply.started": "2025-01-13T13:59:12.712350Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 21:59:20.447410: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-01-13 21:59:20.501460: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-01-13 21:59:21.411399: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model to directory: /mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 21:59:23,242 - modelscope - WARNING - Model revision not specified, use revision: v1.0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c6d09dca3f4045b51844639502ecc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 84 files:   0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51755cc0db24e729b5d85ffc8f288da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/audio_config.yaml]:   0%|          | 0.00/487 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5492bd2d1aa3440f8fad8b1db9ea8250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/audio_config.yaml]:   0%|          | 0.00/487 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c2d9822267d46b0b7eedd2e2f930c5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/audio_config.yaml]:   0%|          | 0.00/487 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680be33a2f6f49a78819d9174cf51ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/voc/ckpt/checkpoint_0.pth]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d05fae5aaf4620868eb94b5f6cdc3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/audio_config.yaml]:   0%|          | 0.00/487 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9355e49c9ec140199bf2c3e272b60b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/am/ckpt/checkpoint_0.pth]:   0%|          | 0.00/47.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f830ee6c40407a96f3bf90019673a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/voc/ckpt/checkpoint_0.pth]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58a458b34482444f8f91c4c7dae4b059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/voc/ckpt/checkpoint_0.pth]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5421626b563546d1ab1154f36e12468c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/am/ckpt/checkpoint_0.pth]:   0%|          | 0.00/47.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8bb044d9452444094a4a94426856774",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/am/ckpt/checkpoint_0.pth]:   0%|          | 0.00/47.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bbf90b8fff44dc6a27c4eca537e9f85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/voc/ckpt/checkpoint_0.pth]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7448862b132f47059150c1e2fb3a1b66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/am/ckpt/checkpoint_0.pth]:   0%|          | 0.00/47.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85bc7a66185244589743f924ab2854ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/voc/ckpt/checkpoint_1.pth]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13cba94a24464753867e62e7e1ead0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/voc/ckpt/checkpoint_1.pth]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1193aadc4baa4bcbbce9559e794f4783",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/voc/ckpt/checkpoint_1.pth]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb751e2b1847415d9ae1c5fe06626bbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/voc/ckpt/checkpoint_1.pth]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca973fdf77c484590558516fea32c4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/voc/config.yaml]:   0%|          | 0.00/5.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb11212f46c14ff0b85edd3db5829a1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/am/config.yaml]:   0%|          | 0.00/3.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0000dc2f9c6249208db900b1e8756cbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/am/config.yaml]:   0%|          | 0.00/3.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "046578a9977947f098c18d21940a86bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/am/config.yaml]:   0%|          | 0.00/3.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1960b9ab158d443780282cd941adb96c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/am/config.yaml]:   0%|          | 0.00/3.22k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f517360936fe45618317396e6f7980d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/voc/config.yaml]:   0%|          | 0.00/5.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ec91af92dc4c3a831a0e666cecc5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/voc/config.yaml]:   0%|          | 0.00/5.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7edcbc2c3c774489943ddaca409ae146",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/voc/config.yaml]:   0%|          | 0.00/5.84k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aceb579ad634ca3b58f6696edafe5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [configuration.json]:   0%|          | 0.00/3.23k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19af781df6474c9796902618b40f5ef0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/emo_category_dict.txt]:   0%|          | 0.00/562 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a481957f87124a83ad2fe932315fb9dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/emo_category_dict.txt]:   0%|          | 0.00/562 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db12f96bf5d7492c8da3676aac5ef8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/emo_category_dict.txt]:   0%|          | 0.00/562 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f11a887ace934d169024641cc2c3c418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/emo_category_dict.txt]:   0%|          | 0.00/562 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed1c84dbf434ec1942be1791f1dd2c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/PinYin/En2ChPhoneMap.txt]:   0%|          | 0.00/10.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d4a05721c44508b5f86fe7dc56c3c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/PinYin/En2ChPhoneMap.txt]:   0%|          | 0.00/10.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2dc59b067954da08b4b2a2e896aefc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/PinYin/En2ChPhoneMap.txt]:   0%|          | 0.00/10.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6f6017f2b43405aba7f3360b9abb6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/PinYin/En2ChPhoneMap.txt]:   0%|          | 0.00/10.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45acac29c3f54157b9d9f9eceb5e1a30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [description/hifigan.png]:   0%|          | 0.00/140k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80baa39250ab4075bedaf3efbe526358",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/PinYin/PhoneSet.xml]:   0%|          | 0.00/22.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce4538b5f479474ebaaf280de3e08d15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/PinYin/PhoneSet.xml]:   0%|          | 0.00/22.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3838758e682b423c9ef37ec7ebd63da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/PinYin/PhoneSet.xml]:   0%|          | 0.00/22.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c17f9f8a064454b113c98fe8c06889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/PinYin/PhoneSet.xml]:   0%|          | 0.00/22.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80e79263ae0c4a9c800edced1a4e6b8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/PinYin/PosSet.xml]:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "375b4273941844759ea0d2821538c7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/PinYin/PosSet.xml]:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e6fc2d8a7c6494bb84f19770b82bd3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/PinYin/PosSet.xml]:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d35ab7582a9474d87673239d549a3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/PinYin/PosSet.xml]:   0%|          | 0.00/2.20k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca5d6021c874920bc9647f55976e041",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/PinYin/py2phoneMap.txt]:   0%|          | 0.00/9.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "caed8b4c096148e3a2778cec07f62689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/PinYin/py2phoneMap.txt]:   0%|          | 0.00/9.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a5d942fff44351b1f8d9735af7aa3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/PinYin/py2phoneMap.txt]:   0%|          | 0.00/9.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "169088aabe47466fb188753cd8844622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/PinYin/py2phoneMap.txt]:   0%|          | 0.00/9.29k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c123a8f5762743749b7f0241993513b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/am/pytorch_model.bin]:   0%|          | 0.00/47.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d968738a12164da88e3fc5b233a92fc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/vocoder/pytorch_model.bin]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78a3d245cc8d46eca148c52af4496ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/am/pytorch_model.bin]:   0%|          | 0.00/47.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e2076124160413386d2dfdeb8d1bd11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/am/pytorch_model.bin]:   0%|          | 0.00/47.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2768ebbdf4774ae3be0acff08b222ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/vocoder/pytorch_model.bin]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54a191b85201449596f1ba5ea347392e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/vocoder/pytorch_model.bin]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b40f39137cc4820b09236d4d44f585a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/vocoder/pytorch_model.bin]:   0%|          | 0.00/18.7M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d33535bf671f43939ef32a356543a586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/am/pytorch_model.bin]:   0%|          | 0.00/47.0M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "226b2e7e780044a6bbd37411e6c808b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/8.12k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1c0e19c8fd4ea8860ef79d60109a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [resource.zip]:   0%|          | 0.00/236M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cae18a72bda549c1b0b7199fb1c66c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [description/sambert.png]:   0%|          | 0.00/137k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75bb05328a074d988992b6ccd7379c4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/speaker_dict.txt]:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97e8d223b46e4be2b1c1b1609818df97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/speaker_dict.txt]:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "490061caf7464fb2a67fc80072bca79a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/speaker_dict.txt]:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d32866019044674b8057957916d53f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/speaker_dict.txt]:   0%|          | 0.00/27.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f0d26af8164fd7b44ba0b9dc0fab7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/sy_dict.txt]:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0a204d1e124b2a9cc7670f55bd21ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/sy_dict.txt]:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89977798602944378ac071daf110975a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/sy_dict.txt]:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33353bcf7c0b4466b8f132b7f1920bec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/sy_dict.txt]:   0%|          | 0.00/653 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f8cee6c223b4491b8311ba478a44331",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/syllable_flag_dict.txt]:   0%|          | 0.00/37.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac6f2d4d6174e4a908ebc0688a5b7cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/syllable_flag_dict.txt]:   0%|          | 0.00/37.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a321ea57795f499caa59f38c9e428c9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/syllable_flag_dict.txt]:   0%|          | 0.00/37.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b112726e4f49cfa622bd10e2515d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/syllable_flag_dict.txt]:   0%|          | 0.00/37.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a671b602329e40f99b1a951cc7bf73ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/tone_dict.txt]:   0%|          | 0.00/46.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da122159b59b4f0587a7a7093c703994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/tone_dict.txt]:   0%|          | 0.00/46.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de01f18dd2649feb1bb6b889a2e5c87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/tone_dict.txt]:   0%|          | 0.00/46.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7242fecbf04f6d85fc5e041ea22b7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/tone_dict.txt]:   0%|          | 0.00/46.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eecff9c615b43a0b069b83ffb923006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/PinYin/tonelist.txt]:   0%|          | 0.00/13.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9265e54ea8d8468598261689f60d512d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/PinYin/tonelist.txt]:   0%|          | 0.00/13.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7918712fc3c44c1b1795b3c06a13c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/PinYin/tonelist.txt]:   0%|          | 0.00/13.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7315fc34ae0467894ca8da725318e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/PinYin/tonelist.txt]:   0%|          | 0.00/13.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8feefb138847a19438d24421cdfe2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [description/tts-system.png]:   0%|          | 0.00/107k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54941d475d204d5292b5ad216e1d68dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/voices.json]:   0%|          | 0.00/94.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4829344e99034539a6c2fc1b6578468b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices.zip]:   0%|          | 0.00/244M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "017a86a2436747af8a3c7a42222050c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhiyan_emo/dict/word_segment_dict.txt]:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfc14e3f42c448139030a87015ebb606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhibei_emo/dict/word_segment_dict.txt]:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "235ea32e95dc48698f340be001398a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhitian_emo/dict/word_segment_dict.txt]:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406c9d59afbc4e148040cc3c8cb367ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [voices/zhizhe_emo/dict/word_segment_dict.txt]:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13 21:59:34,295 - modelscope - INFO - Download model 'iic/speech_sambert-hifigan_tts_zh-cn_16k' successfully.\n",
      "2025-01-13 21:59:35,339 - modelscope - INFO - initiate model from /mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k\n",
      "2025-01-13 21:59:35,340 - modelscope - INFO - initiate model from location /mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k.\n",
      "2025-01-13 21:59:35,345 - modelscope - INFO - initialize model from /mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k\n",
      "2025-01-13 21:59:36,660 - modelscope - INFO - am_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/am/config.yaml voc_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/voc/config.yaml\n",
      "2025-01-13 21:59:36,660 - modelscope - INFO - audio_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/audio_config.yaml\n",
      "2025-01-13 21:59:36,660 - modelscope - INFO - am_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/am/ckpt/checkpoint_0.pth')])\n",
      "2025-01-13 21:59:36,661 - modelscope - INFO - voc_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/voc/ckpt/checkpoint_0.pth'), (1, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/voc/ckpt/checkpoint_1.pth')])\n",
      "2025-01-13 21:59:36,661 - modelscope - INFO - se_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/am/se.npy se_model_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/se/ckpt/se.onnx\n",
      "2025-01-13 21:59:36,662 - modelscope - INFO - mvn_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhitian_emo/am/mvn.npy\n",
      "2025-01-13 21:59:36,707 - modelscope - INFO - am_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/am/config.yaml voc_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/voc/config.yaml\n",
      "2025-01-13 21:59:36,708 - modelscope - INFO - audio_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/audio_config.yaml\n",
      "2025-01-13 21:59:36,708 - modelscope - INFO - am_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/am/ckpt/checkpoint_0.pth')])\n",
      "2025-01-13 21:59:36,708 - modelscope - INFO - voc_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/voc/ckpt/checkpoint_0.pth'), (1, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/voc/ckpt/checkpoint_1.pth')])\n",
      "2025-01-13 21:59:36,709 - modelscope - INFO - se_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/am/se.npy se_model_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/se/ckpt/se.onnx\n",
      "2025-01-13 21:59:36,709 - modelscope - INFO - mvn_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhibei_emo/am/mvn.npy\n",
      "2025-01-13 21:59:36,754 - modelscope - INFO - am_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/am/config.yaml voc_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/voc/config.yaml\n",
      "2025-01-13 21:59:36,754 - modelscope - INFO - audio_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/audio_config.yaml\n",
      "2025-01-13 21:59:36,755 - modelscope - INFO - am_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/am/ckpt/checkpoint_0.pth')])\n",
      "2025-01-13 21:59:36,755 - modelscope - INFO - voc_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/voc/ckpt/checkpoint_0.pth'), (1, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/voc/ckpt/checkpoint_1.pth')])\n",
      "2025-01-13 21:59:36,755 - modelscope - INFO - se_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/am/se.npy se_model_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/se/ckpt/se.onnx\n",
      "2025-01-13 21:59:36,755 - modelscope - INFO - mvn_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhizhe_emo/am/mvn.npy\n",
      "2025-01-13 21:59:36,799 - modelscope - INFO - am_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/am/config.yaml voc_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/voc/config.yaml\n",
      "2025-01-13 21:59:36,800 - modelscope - INFO - audio_config=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/audio_config.yaml\n",
      "2025-01-13 21:59:36,800 - modelscope - INFO - am_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/am/ckpt/checkpoint_0.pth')])\n",
      "2025-01-13 21:59:36,800 - modelscope - INFO - voc_ckpts=OrderedDict([(0, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/voc/ckpt/checkpoint_0.pth'), (1, '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/voc/ckpt/checkpoint_1.pth')])\n",
      "2025-01-13 21:59:36,801 - modelscope - INFO - se_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/am/se.npy se_model_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/se/ckpt/se.onnx\n",
      "2025-01-13 21:59:36,801 - modelscope - INFO - mvn_path=/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k/voices/zhiyan_emo/am/mvn.npy\n",
      "2025-01-13 21:59:45,084 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "2025-01-13 21:59:45,084 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2025-01-13 21:59:45,085 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': '/mnt/workspace/.cache/modelscope/hub/iic/speech_sambert-hifigan_tts_zh-cn_16k'}. trying to build by task and model information.\n",
      "2025-01-13 21:59:45,085 - modelscope - WARNING - No preprocessor key ('sambert-hifigan', 'text-to-speech') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/queueing.py\", line 715, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/blocks.py\", line 2042, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/blocks.py\", line 1601, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 728, in async_iteration\n",
      "    return await anext(iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 722, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 705, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 866, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "  File \"/tmp/ipykernel_197/2199858804.py\", line 354, in run_flow\n",
      "    generate_results = asyncio.run(generate_media(infos))\n",
      "  File \"/usr/local/lib/python3.10/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"/tmp/ipykernel_197/2199858804.py\", line 230, in generate_media\n",
      "    return await asyncio.gather(\n",
      "  File \"/tmp/ipykernel_197/2199858804.py\", line 220, in generate_image\n",
      "    rsp = ImageSynthesis.call(model=\"flux-dev\",\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/aigc/image_synthesis.py\", line 65, in call\n",
      "    return super().call(model,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/client/base_api.py\", line 217, in call\n",
      "    response = cls.wait(task_response,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/aigc/image_synthesis.py\", line 196, in wait\n",
      "    response = super().wait(task, api_key, workspace=workspace)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/client/base_api.py\", line 377, in wait\n",
      "    task_id = cls._get_task_id(task)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/client/base_api.py\", line 230, in _get_task_id\n",
      "    raise InvalidTask('Invalid task, task create failed: %s' %\n",
      "dashscope.common.error.InvalidTask: Invalid task, task create failed: {\"status_code\": 401, \"request_id\": \"67f550f1-2cc8-9e5b-854e-ec93e4252e43\", \"code\": \"InvalidApiKey\", \"message\": \"Invalid API-key provided.\", \"output\": null, \"usage\": null}\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/queueing.py\", line 715, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/blocks.py\", line 2042, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/blocks.py\", line 1601, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 728, in async_iteration\n",
      "    return await anext(iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 722, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 705, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 866, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "  File \"/tmp/ipykernel_197/2199858804.py\", line 354, in run_flow\n",
      "    generate_results = asyncio.run(generate_media(infos))\n",
      "  File \"/usr/local/lib/python3.10/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"/tmp/ipykernel_197/2199858804.py\", line 230, in generate_media\n",
      "    return await asyncio.gather(\n",
      "  File \"/tmp/ipykernel_197/2199858804.py\", line 220, in generate_image\n",
      "    rsp = ImageSynthesis.call(model=\"flux-dev\",\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/aigc/image_synthesis.py\", line 65, in call\n",
      "    return super().call(model,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/client/base_api.py\", line 217, in call\n",
      "    response = cls.wait(task_response,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/aigc/image_synthesis.py\", line 196, in wait\n",
      "    response = super().wait(task, api_key, workspace=workspace)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/client/base_api.py\", line 377, in wait\n",
      "    task_id = cls._get_task_id(task)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/client/base_api.py\", line 230, in _get_task_id\n",
      "    raise InvalidTask('Invalid task, task create failed: %s' %\n",
      "dashscope.common.error.InvalidTask: Invalid task, task create failed: {\"status_code\": 401, \"request_id\": \"ec87c891-7f49-9e55-a2a6-dc40a0e2622e\", \"code\": \"InvalidApiKey\", \"message\": \"Invalid API-key provided.\", \"output\": null, \"usage\": null}\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/queueing.py\", line 715, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/route_utils.py\", line 322, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/blocks.py\", line 2042, in process_api\n",
      "    result = await self.call_function(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/blocks.py\", line 1601, in call_function\n",
      "    prediction = await utils.async_iteration(iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 728, in async_iteration\n",
      "    return await anext(iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 722, in __anext__\n",
      "    return await anyio.to_thread.run_sync(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/anyio/to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 2441, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "  File \"/usr/local/lib/python3.10/site-packages/anyio/_backends/_asyncio.py\", line 943, in run\n",
      "    result = context.run(func, *args)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 705, in run_sync_iterator_async\n",
      "    return next(iterator)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/gradio/utils.py\", line 866, in gen_wrapper\n",
      "    response = next(iterator)\n",
      "  File \"/tmp/ipykernel_197/2199858804.py\", line 354, in run_flow\n",
      "    generate_results = asyncio.run(generate_media(infos))\n",
      "  File \"/usr/local/lib/python3.10/asyncio/runners.py\", line 44, in run\n",
      "    return loop.run_until_complete(main)\n",
      "  File \"uvloop/loop.pyx\", line 1518, in uvloop.loop.Loop.run_until_complete\n",
      "  File \"/tmp/ipykernel_197/2199858804.py\", line 230, in generate_media\n",
      "    return await asyncio.gather(\n",
      "  File \"/tmp/ipykernel_197/2199858804.py\", line 220, in generate_image\n",
      "    rsp = ImageSynthesis.call(model=\"flux-dev\",\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/aigc/image_synthesis.py\", line 65, in call\n",
      "    return super().call(model,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/client/base_api.py\", line 217, in call\n",
      "    response = cls.wait(task_response,\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/aigc/image_synthesis.py\", line 196, in wait\n",
      "    response = super().wait(task, api_key, workspace=workspace)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/client/base_api.py\", line 377, in wait\n",
      "    task_id = cls._get_task_id(task)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/dashscope/client/base_api.py\", line 230, in _get_task_id\n",
      "    raise InvalidTask('Invalid task, task create failed: %s' %\n",
      "dashscope.common.error.InvalidTask: Invalid task, task create failed: {\"status_code\": 401, \"request_id\": \"75127c8b-b015-982a-81fc-8ac9fd01017e\", \"code\": \"InvalidApiKey\", \"message\": \"Invalid API-key provided.\", \"output\": null, \"usage\": null}\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "from gradio.route_utils import get_root_url\n",
    "from openai import OpenAI\n",
    "import modelscope_studio.components.base as ms\n",
    "import modelscope_studio.components.legacy as legacy\n",
    "import modelscope_studio.components.antd as antd\n",
    "from modelscope.outputs import OutputKeys\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.utils.constant import Tasks\n",
    "from dashscope import ImageSynthesis\n",
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import base64\n",
    "import re\n",
    "import requests\n",
    "import asyncio\n",
    "from string import Template\n",
    "from http import HTTPStatus\n",
    "\n",
    "\n",
    "GenerateWordInfoSystemPrompt = \"\"\"\n",
    "你是英文单词记忆卡的编撰者，精通 JSON 数据集格式，请根据以下提示，生成一个英语单词记忆卡所需的所有信息，按照以下的 key 来生成 JSON:\n",
    "- title：提取出的英文单词\n",
    "- phonetic_symbols: 英文单词的音标\n",
    "- translation_meaning: 英文单词的中文含义，用全中文输出\n",
    "- etymological_explanation: 英文单词的词源解释，用全中文输出\n",
    "- example_sentence: 英文单词的例句，用上述单词写一个例句，尽量能让人有画面感，用英文输出\n",
    "- example_sentence_image_prompt: 使用 example_sentence 的例句内容扩充出来一个用来描述生成图片内容的 Prompt，需要突出例句中的单词，用英文输出\n",
    "仅输出 JSON 内容，不返回 JSON 以外的任何内容。\n",
    "\"\"\"\n",
    "\n",
    "GenerateUiCodeSystemPrompt = \"\"\"\n",
    "你是一个网页开发工程师，根据下面的指示编写网页。\n",
    "所有代码写在一个代码块中，形成一个完整的代码文件进行展示，不用将HTML代码和JavaScript代码分开。\t\n",
    "**你更倾向集成并输出这类完整的可运行代码，而非拆分成若干个代码块输出**。\n",
    "对于部分类型的代码能够在UI窗口渲染图形界面，生成之后请你再检查一遍代码运行，确保输出无误。\n",
    "仅输出 html，不要附加任何描述文案。\n",
    "\"\"\"\n",
    "\n",
    "GenerateUiCodePromptTemplate = \"\"\"\n",
    "创建一个HTML页面，用于介绍英语单词 $title 的词源、含义及用法。页面应该包括以下部分：\n",
    "\n",
    "- **标题区域**：分成三行展示单词“$title”及其音标 $phonetic_symbols 和基本含义:$translation_meaning。字体颜色为深绿色。\n",
    "- **词源解释区域**：$etymological_explanation。字体颜色为深灰色。\n",
    "- **图片带链接区域**：包含一张与单词相关的图片，图片链接为 $image_url。\n",
    "- **例句区域**：提供一个使用单词 $title 的例句：“$example_sentence” 其中“$title”一词被高亮显示为深绿色，其他颜色为深灰色。英文显示。\n",
    "- **播放例句**：提供一个音频播放按钮，按钮上有文字“播放例句”，点击后播放一段音频，音频链接为：$audio_url。\n",
    "请确保页面布局美观，易于阅读，所有的内容居中对齐，不限制页面高度，背景颜色为浅色，边框颜色为深绿色。\n",
    "\"\"\"\n",
    "\n",
    "DEMO_LIST = [\n",
    "  {\n",
    "    \"card\": {\n",
    "      \"index\": 0,\n",
    "    },\n",
    "    \"title\": \"abandon🤷‍♂️\",\n",
    "    \"description\": \"帮我记一下 abandon\"\n",
    "  },\n",
    "  {\n",
    "    \"card\": {\n",
    "      \"index\": 1,\n",
    "    },\n",
    "    \"title\": \"长颈鹿🦒\",\n",
    "    \"description\": \"长颈鹿的单词是什么呢\"\n",
    "  },\n",
    "  {\n",
    "    \"card\": {\n",
    "      \"index\": 2,\n",
    "    },\n",
    "    \"title\": \"随便来个🎲\",\n",
    "    \"description\": \"帮我随机找一个生僻的单词\"\n",
    "  },\n",
    "  {\n",
    "    \"card\": {\n",
    "      \"index\": 3,\n",
    "    },\n",
    "    \"title\": \"天气🌞\",\n",
    "    \"description\": \"帮我找个描述天气的单词\"\n",
    "  }\n",
    "]\n",
    "\n",
    "css = \"\"\"\n",
    ".left_header {\n",
    "  display: flex;\n",
    "  flex-direction: column;\n",
    "  justify-content: center;\n",
    "  align-items: center;\n",
    "}\n",
    "\n",
    ".right_panel {\n",
    "  border: 1px solid #BFBFC4;\n",
    "  border-radius: 8px;\n",
    "  padding: 16px;\n",
    "  min-height: 90vh;\n",
    "  display: flex;\n",
    "  justify-content: center;\n",
    "  align-items: center;\n",
    "}\n",
    "\n",
    ".sandbox_output {\n",
    "  margin-top: 16px;\n",
    "  border: 1px solid #BFBFC4;\n",
    "  border-radius: 8px;\n",
    "  padding: 16px;\n",
    "}\n",
    "\n",
    ".step_container {\n",
    "  padding: 20px 0;\n",
    "}\n",
    "\n",
    ".display_chatbot button {\n",
    "  background: none;\n",
    "  border: none;\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "directory_path = \"output_assets\"\n",
    "if not os.path.exists(directory_path):\n",
    "    os.makedirs(directory_path)\n",
    "    \n",
    "\n",
    "MODELSCOPE_ACCESS_TOKEN = os.getenv(\"MODELSCOPE_ACCESS_TOKEN\")\n",
    "\n",
    "# 初始化 OpenAI 客户端\n",
    "client = OpenAI(\n",
    "    api_key=MODELSCOPE_ACCESS_TOKEN,\n",
    "    base_url=\"https://api-inference.modelscope.cn/v1\"\n",
    ")\n",
    "\n",
    "audio_model_id = 'iic/speech_sambert-hifigan_tts_zh-cn_16k'\n",
    "sambert_hifigan_tts = pipeline(task=Tasks.text_to_speech, model=audio_model_id)\n",
    "\n",
    "def resolve_assets(relative_path):\n",
    "    return os.path.join(os.getcwd(), directory_path, relative_path)\n",
    "\n",
    "def demo_card_click(e: gr.EventData):\n",
    "    index = e._data['component']['index']\n",
    "    return DEMO_LIST[index]['description']\n",
    "\n",
    "def covert_display_messages(display_messages):\n",
    "  return [{'role': m['role'] == 'user' and 'user' or 'assistant', 'content': m['content']} for m in display_messages]\n",
    "\n",
    "def remove_code_block(text):\n",
    "    pattern = r'```html\\n(.+?)\\n```'\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(1).strip()\n",
    "    else:\n",
    "        return text.strip()\n",
    "\n",
    "def send_to_sandbox(code):\n",
    "    encoded_html = base64.b64encode(code.encode('utf-8')).decode('utf-8')\n",
    "    data_uri = f\"data:text/html;charset=utf-8;base64,{encoded_html}\"\n",
    "    return f\"<iframe src=\\\"{data_uri}\\\" width=\\\"100%\\\" height=\\\"920px\\\"></iframe>\"\n",
    "\n",
    "def generate_word_info(query, display_messages):\n",
    "  messages = [\n",
    "    {'role': 'system', 'content': GenerateWordInfoSystemPrompt},\n",
    "    {'role': 'user', 'content': query},\n",
    "  ]\n",
    "\n",
    "  display_messages = messages\n",
    "  yield {\n",
    "    \"display_messages\": display_messages,\n",
    "    \"is_stop\": False,\n",
    "  }\n",
    "  try:\n",
    "    gen = client.chat.completions.create(\n",
    "      model=\"Qwen/Qwen2.5-32B-Instruct\",\n",
    "      messages=messages,\n",
    "      stream=True\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "    display_messages.append({'role': 'assistant', 'content': full_response})\n",
    "    for chunk in gen:\n",
    "      content = chunk.choices[0].delta.content\n",
    "      full_response += content\n",
    "      display_messages[-1]['content'] = full_response\n",
    "      is_stop = chunk.choices[0].finish_reason == 'stop'\n",
    "      yield {\n",
    "         \"display_messages\": display_messages,\n",
    "         \"content\": full_response,\n",
    "         \"is_stop\": is_stop,\n",
    "      }            \n",
    "  except Exception as e:\n",
    "    yield {\n",
    "      \"content\": str(e),\n",
    "      \"is_stop\": True,\n",
    "    }\n",
    "\n",
    "async def generate_audio(query):\n",
    "  output = sambert_hifigan_tts(input=query, voice='zhitian_emo')\n",
    "  wav = output[OutputKeys.OUTPUT_WAV]\n",
    "  timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "  filename = f\"{timestamp}.wav\"\n",
    "  file_path = os.path.join(directory_path, filename)\n",
    "  with open(file_path, 'wb') as f:\n",
    "    f.write(wav)\n",
    "  return resolve_assets(filename)\n",
    "\n",
    "async def generate_image(query):\n",
    "  # try:\n",
    "  #   payload = {\"input\": {\"text\": query}, \"parameters\": {\"tokenizer\": \"xglm\", \"batch_size\": 1}}\n",
    "  #   API_URL = \"https://api-inference.modelscope.cn/api-inference/v1/models/iic/cv_diffusion_text-to-image-synthesis\"\n",
    "  #   headers = {\"Authorization\": f\"Bearer {MODELSCOPE_ACCESS_TOKEN}\"}\n",
    "  #   data = json.dumps(payload)\n",
    "  #   response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
    "  #   if response.status_code == 200:\n",
    "  #     res_json = response.json()\n",
    "  #     print(res_json)\n",
    "  #     image_url = res_json[\"data\"][\"output_imgs\"][0]\n",
    "  #   else:\n",
    "  #     raise Exception(f\"请求失败，状态码: {response.status_code}\")\n",
    "  # except Exception as e:\n",
    "  #   print(e)\n",
    "  #   image_url = \"\"\n",
    "  # return image_url\n",
    "  rsp = ImageSynthesis.call(model=\"flux-dev\",\n",
    "                            prompt=query,\n",
    "                            size='768*512')\n",
    "  if rsp.status_code == HTTPStatus.OK:\n",
    "    return rsp.output.results[0].url\n",
    "  else:\n",
    "    print('Failed, status_code: %s, code: %s, message: %s' %\n",
    "              (rsp.status_code, rsp.code, rsp.message))\n",
    "\n",
    "async def generate_media(infos):\n",
    "  return await asyncio.gather(\n",
    "      generate_audio(infos['example_sentence']),\n",
    "      generate_image(infos['example_sentence_image_prompt'])\n",
    "    )\n",
    "\n",
    "def generate_ui_code(infos, display_messages):\n",
    "  template = Template(GenerateUiCodePromptTemplate)\n",
    "  prompt = template.substitute(infos)\n",
    "  print('generate_ui_code:', prompt)\n",
    "  messages = [\n",
    "    {'role': 'system', 'content': GenerateUiCodeSystemPrompt },\n",
    "    {'role': 'user', 'content': prompt},\n",
    "  ]\n",
    "\n",
    "  display_messages = display_messages + messages\n",
    "\n",
    "  try:\n",
    "    gen = client.chat.completions.create(\n",
    "      model=\"Qwen/Qwen2.5-32B-Instruct\",\n",
    "      messages=messages,\n",
    "      stream=True\n",
    "    )\n",
    "    \n",
    "    full_response = \"\"\n",
    "    display_messages.append({'role': 'assistant', 'content': full_response})\n",
    "    for chunk in gen:\n",
    "      content = chunk.choices[0].delta.content\n",
    "      full_response += content\n",
    "      display_messages[-1]['content'] = full_response\n",
    "      is_stop = chunk.choices[0].finish_reason == 'stop'\n",
    "      yield {\n",
    "        \"display_messages\": display_messages,\n",
    "        \"content\": full_response,\n",
    "        \"is_stop\": is_stop,\n",
    "      }     \n",
    "  except Exception as e:\n",
    "    yield {\n",
    "      \"display_messages\": display_messages,\n",
    "      \"content\": str(e),\n",
    "      \"is_stop\": True,\n",
    "    }\n",
    "    \n",
    "# 仅在 Notebook 中使用需要以下代码，如果之前已经定义过 `app`，关闭它\n",
    "try:\n",
    "    demo.close()\n",
    "except NameError:\n",
    "    # 如果 `app` 不存在，忽略这个异常\n",
    "    pass\n",
    "    \n",
    "with gr.Blocks(css=css) as demo:\n",
    "    history = gr.State([])\n",
    "\n",
    "    with ms.Application():\n",
    "        with antd.ConfigProvider(locale=\"zh_CN\"):\n",
    "            with antd.Row(gutter=[32, 12]) as layout:\n",
    "                with antd.Col(span=24, md=8):\n",
    "                    with antd.Flex(vertical=True, gap=\"middle\", wrap=True):\n",
    "                        header = gr.HTML(\"\"\"\n",
    "                                  <div class=\"left_header\">\n",
    "                                    <img src=\"//img.alicdn.com/imgextra/i3/O1CN01Q501Kf1IjzMXFpjvL_!!6000000000930-0-tps-768-1024.jpg\" width=\"200px\" />\n",
    "                                   <h2>随心单词卡</h2>\n",
    "                                  </div>\n",
    "                                   \"\"\")\n",
    "                        input = antd.InputTextarea(\n",
    "                            size=\"large\", allow_clear=True, placeholder=\"请输入你想要记什么单词？\")\n",
    "                        btn = antd.Button(\"生成\", type=\"primary\", size=\"large\")\n",
    "\n",
    "                        antd.Divider(\"示例\")\n",
    "                        with antd.Flex(gap=\"small\", wrap=True):\n",
    "                            with ms.Each(DEMO_LIST):\n",
    "                              with antd.Card(hoverable=True, as_item=\"card\") as demoCard:\n",
    "                                antd.CardMeta()\n",
    "                              demoCard.click(demo_card_click, outputs=[input])\n",
    "\n",
    "                        antd.Divider(\"设置\")\n",
    "                        view_process_btn = antd.Button(\"查看生成过程\")\n",
    "\n",
    "                with antd.Col(span=24, md=16):\n",
    "                    with ms.Div(elem_classes=\"right_panel\"):\n",
    "                        with antd.Drawer(open=False, width=\"1200\", title=\"生成过程\") as drawer:\n",
    "                          with ms.Div(elem_classes=\"step_container\"):\n",
    "                            with antd.Steps(0) as steps:\n",
    "                              antd.Steps.Item(title=\"容我查一下词典\", description=\"正在生成单词的各类信息\")\n",
    "                              antd.Steps.Item(title=\"容我补些素材\", description=\"正在生成单词例句的助记图和发音\")\n",
    "                              antd.Steps.Item(title=\"即将大功告成\", description=\"正在生成单词卡的界面\")\n",
    "                          display_chatbot = gr.Chatbot(type=\"messages\", elem_classes=\"display_chatbot\", height=800, show_label=False, )\n",
    "                                  \n",
    "                        sandbox_output = gr.HTML(\"\"\"\n",
    "                            <div align=\"center\">\n",
    "                              <h4>在左侧输入或选择你想要的单词卡开始制作吧～</h4>\n",
    "                            </div>\n",
    "                        \"\"\")\n",
    "                        \n",
    "    view_process_btn.click(lambda : gr.update(open=True), outputs=[drawer])\n",
    "    drawer.close(lambda: gr.update(\n",
    "                        open=False), inputs=[], outputs=[drawer])\n",
    "\n",
    "    def run_flow(query, request: gr.Request):\n",
    "      display_messages = []\n",
    "      yield {\n",
    "        steps: gr.update(current=0),\n",
    "        drawer: gr.update(open=True),\n",
    "      }\n",
    "      for info_result in generate_word_info(query, display_messages):\n",
    "\n",
    "        if info_result['is_stop']:\n",
    "            word_info_str = info_result['content']\n",
    "            break\n",
    "        else:\n",
    "            yield {\n",
    "              display_chatbot: covert_display_messages(info_result['display_messages']),\n",
    "            }\n",
    "      infos = json.loads(word_info_str)\n",
    "      yield {\n",
    "        steps: gr.update(current=1),\n",
    "        display_chatbot: covert_display_messages(info_result['display_messages']),\n",
    "      }\n",
    "      display_messages.append({\n",
    "        'role': 'assistant',\n",
    "        'content': f\"根据这些内容生成插图和例句发音:\\n 插图：{infos['example_sentence_image_prompt']}\\n 例句发音：{infos['example_sentence']}\",\n",
    "      })\n",
    "      yield {\n",
    "        display_chatbot: covert_display_messages(display_messages),\n",
    "      }\n",
    "      generate_results = asyncio.run(generate_media(infos))\n",
    "      root = get_root_url(\n",
    "        request=request, route_path=\"/gradio_api/queue/join\", root_path=demo.root_path\n",
    "      )\n",
    "      root = root.replace(\"http:\", \"https:\")\n",
    "      print('root:', root)\n",
    "      infos['audio_url'] = f\"{root}/gradio_api/file={demo.move_resource_to_block_cache(generate_results[0])}\"\n",
    "      infos['image_url'] = generate_results[1]\n",
    "      yield {\n",
    "        steps: gr.update(current=2),\n",
    "      }\n",
    "      for ui_code_result in generate_ui_code(infos, display_messages):\n",
    "        if ui_code_result['is_stop']:\n",
    "          ui_code_str = ui_code_result['content']\n",
    "          break\n",
    "        else:\n",
    "          yield {\n",
    "            display_chatbot: covert_display_messages(ui_code_result['display_messages']),\n",
    "          }\n",
    "      yield {\n",
    "        drawer: gr.update(open=False),\n",
    "        display_chatbot: covert_display_messages(ui_code_result['display_messages']),\n",
    "        sandbox_output: send_to_sandbox(remove_code_block(ui_code_str)),\n",
    "      }\n",
    "\n",
    "    btn.click(run_flow, inputs=[input], outputs=[steps, drawer, display_chatbot, sandbox_output])\n",
    "\n",
    "# 启动 Gradio 应用\n",
    "demo.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
